# AUTOGENERATED! DO NOT EDIT! File to edit: UniversalFunctionApproximator/UFA_steam_example.ipynb (unless otherwise specified).

__all__ = ['npt', 'get_config', 'print_run', 'create_iap_data', 'iap3d', 'fcnet', 'get_dataloader', 'weights_xavier',
           'fit_model', 'visualize_results', 'cfg', 'iap_df', 'dl', 'iap_net', 'model_stats', 'epoch_loss',
           'epoch_loss', 'epoch_loss', 'inference_all', 'prediction', 'example', 'traced_script_module', 'output',
           'x_in']

# Cell
# Nested list comprehension
# matrix = [[j for j in range(5)] for i in range(5)]
print("Imports section ***** \n\n")
from iapws import IAPWS95
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.preprocessing import MinMaxScaler
from sklearn import preprocessing
from numpy import savetxt

import torch
from torch.autograd import Variable
import torch.nn.functional as F
import torch.utils.data as Data
import imageio
from livelossplot import PlotLosses
import sys
from sklearn import preprocessing
from IPython.display import display
from iapws import IAPWS95



# Cell
print("Define Configuration ***** \n\n")
def npt(mystring) :
    print("**{}** : {}".format(sys._getframe(1).f_code.co_name,mystring))

def get_config(cfg_in={}):
    config = {}
    # Tx = 10          # variable per batch sequence length
    config["device"] = "cuda"
    config["hidden_size"] = 2000  # number of features of hidden state
    config["num_layers"]  = 1  # this is for stacked implementations.  Keep 1 for now
    config["num_epochs"]  = 300  # this is for stacked implementations.  Keep 1 for now
    config["batch_size"] = 8
    config["test_batch_size"] = 64
    config["weight_decay"]=0.00
    config["learning_rate"]=0.00005
    config["tls"]=(275,393,30)
    config["vls"]=(6.85,120,30)

    # overwrite configs if passed
    for (k,v) in cfg_in.items() :
        npt("Overriding Config {}:{} with {}".format(k,config[k],v))
        config[k] = v
    return config

# config.items
def print_run(config) :
    npt("Project Configuration")
    for k,v in sorted(config.items()) :
        # print(i)
        print("{}:{}".format(k,v))

print_run(get_config({"learning_rate":0.01}))

# Cell
print("Create Dataset section ***** \n\n")
def create_iap_data(cfg, normalize=True) :
    vls =np.linspace(*cfg['vls'])
    tls =np.linspace(*cfg['tls'])
    rv = [[[t,v,IAPWS95(T = t, v = v).P] for v in vls] for t in tls]
    rv = np.asarray(rv)
    # Take the values calculated along Temp/SpecV axes and just flatten into columns..
    rv = rv.reshape(-1,3)
    df = pd.DataFrame(rv,columns=["x0_Temp","x1_SpecificVol","y_Pressure"])
    print("Created data array of size : {}".format(rv.shape))
    print("Returning Pandas Dataframe ")

    if(normalize==True):
        x = df.values #returns a numpy array
        std_scaler = preprocessing.StandardScaler()
        x_scaled = std_scaler.fit_transform(x)
        df = pd.DataFrame(x_scaled,columns=["x0_Temp","x1_SpecificVol","y_Pressure"])
    return df


# Cell
print("3D Plotting Utilty section ***** \n\n")
import plotly.figure_factory as ff
import plotly.io as pio
pio.renderers.default = "iframe_connected"
from scipy.spatial import Delaunay

def iap3d(cfg,z_evaled):

    u = np.linspace(*cfg['tls'])
    v = np.linspace(*cfg['vls'])
    print("ushape pre meshgrid : {}".format(u.shape))
    print("vshape pre meshgrid : {}".format(v.shape))
    u,v = np.meshgrid(u,v)
    print("ushape post meshgrid : {}".format(u.shape))
    print("vshape post meshgrid : {}".format(v.shape))

    u = u.flatten()
    v = v.flatten()

    x=u
    y=v
    z = z_evaled  # already evaluated...

    print("x  : {}".format(x.shape))
    print("y  : {}".format(y.shape))
    print("z  : {}".format(z.shape))

    points2D = np.vstack([u,v]).T
    print("points2D  : {}".format(points2D.shape))
    tri = Delaunay(points2D)  # https://en.wikipedia.org/wiki/Delaunay_triangulation
    simplices = tri.simplices
    simplices.shape
    print("points2D  : {}".format(points2D.shape))
#
    fig = ff.create_trisurf(x=x, y=y, z=z,
                             simplices=simplices,
                             title="Iap3D", aspectratio=dict(x=1, y=1, z=0.3),)
    return fig

# Test this ... Requires exact same config that was used to build your dataframe ...


# Cell
print("Define Model section ***** \n\n")
def fcnet(cfg):
    net = torch.nn.Sequential(
        torch.nn.Linear(2, cfg["hidden_size"], bias=True),
        torch.nn.ReLU(),
        torch.nn.Linear(cfg["hidden_size"], 1, bias=True),
        #torch.nn.ReLU(),
        #torch.nn.Linear(cfg["hidden_size"], 1, bias=True),
    )
    return net

# Cell
print("Define Dataloader section ***** \n\n")
def get_dataloader(cfg,iap_data):
    x = torch.Tensor(iap_data.iloc[:,0:2].values)
    y = torch.Tensor(iap_data.iloc[:,2].values)
    npt(" X shape:{}".format(x.size()))
    npt(" Y shape:{}".format(y.size()))
    # x = x.reshape(-1,2)
    # y = y.reshape(-1,1)
    # npt("Reshaped X shape:{}".format(x.size()))
    # npt("Reshaped Y shape:{}".format(y.size()))

    torch_dataset = Data.TensorDataset(x, y)
    loader = Data.DataLoader(
        dataset=torch_dataset,
        batch_size=cfg["batch_size"],
        shuffle=True, num_workers=8,)
    npt("Num batches :{}".format(len(loader)))
    return loader

# Cell
print("Initialize Weights section ***** \n\n")
# Initialize with Xavier normal distribuition
from torch.nn.init import xavier_normal_ , uniform_

def weights_xavier(m):
    if isinstance(m, torch.nn.Conv2d):
        xavier_normal_(m.weight.data)
    elif isinstance(m, torch.nn.Linear) :
        xavier_normal_(m.weight.data)
        m.bias.data.fill_(0)


# Cell
print("Fit Model function def section ***** \n\n")
def fit_model(cfg,net,loader,verbose=False ) :
    optimizer = torch.optim.Adam(net.parameters(), lr=cfg["learning_rate"], weight_decay=cfg["weight_decay"])
    loss_func = torch.nn.MSELoss() # this is for regression mean squared loss
    # Setup Pytorch in training mode
    net.train()
    # start training
    loss_hist = {}
    liveloss = PlotLosses()
    logs = {}
    lowest = 999999

    best_params = None
    for epoch in range(cfg["num_epochs"]):
        epoch_loss = 0
        for step, (batch_x, batch_y) in enumerate(loader): # for each training step
            prediction = net(batch_x).reshape(-1)     # input x and predict based on x
            if verbose :npt("batch_x.size:{}".format(batch_x.size()))
            if verbose :npt("batch_y.size:{}".format(batch_y.size()))
            if verbose :npt("prediction.size:{}".format(prediction.size()))

            loss = loss_func(prediction, batch_y)     # must be (1. nn output, 2. target)
            epoch_loss += loss.detach().cpu().numpy()
            optimizer.zero_grad()   # clear gradients for next train
            loss.backward()         # backpropagation, compute gradients
            optimizer.step()        # apply gradients

        epoch_loss = epoch_loss / 900

        # Draw Loss curves, gradients, and current inference results...
        visualize_results(cfg,epoch,liveloss,epoch_loss,loss_hist,net)
        print("epoch_loss {}".format(epoch_loss))
        pstr = '\repoch: {},  lr: {}, lowest_loss: {:7.5e}, latest_loss: {:7.5e}\n'.format(epoch, cfg["learning_rate"], lowest, epoch_loss)
        print(pstr,end="")
    return epoch_loss

# uses global iap_df as closure for now
def visualize_results(cfg,epoch,liveloss,epoch_loss,loss_hist,net) :
    if epoch > 1:
        if epoch_loss < min(loss_hist):
            best_params = net #copy()
            lowest = min(loss_hist)
    loss_hist[epoch] = epoch_loss

    if(epoch_loss < 0.10):
            liveloss.update({
                'clipped loss': epoch_loss,
                'log_loss': np.log10(epoch_loss)
            })
    else:
        liveloss.update({
            'clipped loss': 0.10,
            'log_loss': np.log10(epoch_loss)
        })

    # figure = iap3d(cfg,iap_df["y_Pressure"].values)
    liveloss.draw()
    # Get Current prediction and graph it!
    cur_prediction = net(torch.tensor(iap_df.iloc[:,0:2].values, dtype=torch.float))
    cur_prediction = cur_prediction.detach().cpu().reshape(-1).numpy()
    figure = iap3d(cfg,cur_prediction)
    #figure.show()
    figure.show(renderer="iframe_connected")

# Cell
print("Run Job section ***** \n\n")
# Setup Run Configuration
cfg=get_config({'num_epochs' : 60})
print(cfg)

# Build Dataset
iap_df = create_iap_data(cfg)
display(iap_df.describe())
iap3d(cfg,iap_df["y_Pressure"].values)

# Cell
print("get_dataloader section ***** \n\n")
# Create DataLoader
dl = get_dataloader(cfg,iap_df)

# Cell
print("Build Model section ***** \n\n")
# Build Model
iap_net = fcnet(cfg)
# Initialize Model
iap_net.apply(weights_xavier)

# Cell
print("def model_stats section ***** \n\n")
# Simple model stats
# plot just the first convolutional layer weight distribution
def model_stats(model):
    for idx, (n,m) in enumerate(model.named_modules()):
        if(isinstance(m,torch.nn.modules.Linear)) :
            #print(n,m, m.weight.size())
            parmeters = m.weight.detach().cpu().numpy().flatten()
            print("n:{} m:{} param mean:{}, std :{}".format(n, m, np.mean(parmeters), np.std(parmeters)))
            #print(m)

# test
model_stats(fcnet(cfg))

# Cell
print("print model_stats section ***** \n\n")
model_stats(iap_net)

# Cell
print("Train Model LR = 0.001 section ***** \n\n")
# Train Model
epoch_loss = fit_model(get_config({"num_epochs":6,"learning_rate":0.001}),iap_net,dl)

# Cell
print("Train Model LR = 0.0005 section ***** \n\n")
# Train Model
epoch_loss = fit_model(get_config({"num_epochs":6,"learning_rate":0.0005}),iap_net,dl)

# Cell
print("Train Model LR = 0.0001 section ***** \n\n")
epoch_loss = fit_model(get_config({"num_epochs":6,"learning_rate":0.0001}),iap_net,dl)

# Cell
print("def inference_all section ***** \n\n")
def inference_all() :
    iap_net.eval()
    #prediction = net(b_x)
    x = torch.tensor(iap_df.iloc[:,0:2].values, dtype=torch.float)
    print(x.shape)
    prediction = iap_net(x)
    prediction.flatten().size()
    return prediction
    #YP = prediction.detach().cpu().numpy().squeeze()
    #Y_STANDARD
prediction = inference_all()

# Cell
print("jit trace section ***** \n\n")
# Convert a PyTorch model to Torch Script via tracing
example = torch.tensor(iap_df.iloc[:,0:2].values, dtype=torch.float)
traced_script_module = torch.jit.trace(iap_net, example)

# Cell
print("traced_script_module ***** \n\n")
# Torch Script behaves just like pytorch model
output = traced_script_module(example)

# Cell
print("Serialize Torchscript Module  ***** \n\n")
# Serialize Torchscript Module
traced_script_module.save("traced_ufa_ts.pt")

# Cell
print("Example Inference  ***** \n\n")
x_in = torch.ones([2, 2])
print(iap_net(x_in))
