{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "[Credit : This notebook was copied and modified from Udacity Deep Learning course]\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the MNIST dataset. From this, we'll be able to generate new handwritten digits!\n",
    "\n",
    "GANs were [first reported on](https://arxiv.org/abs/1406.2661) in 2014 from Ian Goodfellow and others in Yoshua Bengio's lab. Since then, GANs have exploded in popularity. Here are a few examples to check out:\n",
    "\n",
    "* [Pix2Pix](https://affinelayer.com/pixsrv/) \n",
    "* [CycleGAN](https://github.com/junyanz/CycleGAN)\n",
    "* [A whole list](https://github.com/wiseodd/generative-models)\n",
    "\n",
    "The idea behind GANs is that you have two networks, a generator $G$ and a discriminator $D$, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it's received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks _as close as possible_ to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistiguishable from real data to the discriminator.\n",
    "\n",
    "![GAN diagram](assets/gan_diagram.png)\n",
    "\n",
    "The general structure of a GAN is shown in the diagram above, using MNIST images as data. The latent sample is a random vector the generator uses to contruct it's fake images. As the generator learns through training, it figures out how to map these random vectors to recognizable images that can fool the discriminator.\n",
    "\n",
    "The output of the discriminator is a sigmoid function, where 0 indicates a fake image and 1 indicates an real image. If you're interested only in generating new images, you can throw out the discriminator after training. Now, let's see how we build this thing in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:17:45.913930Z",
     "start_time": "2020-07-28T20:17:45.908793Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training And Valiation Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:10:58.135109Z",
     "start_time": "2020-07-29T14:10:55.875250Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset = datasets.MNIST('./datasets', download=True, train=True, transform=transform)\n",
    "\n",
    "valset = datasets.MNIST('./datasets', download=True, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display A Few Images From The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:11:01.482347Z",
     "start_time": "2020-07-29T14:11:01.259265Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(5,5), nrows=2, ncols=2, sharey=True, sharex=True)\n",
    "for ax, img in zip(axes.flatten(), images[12:16]):\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    im = ax.imshow(img.detach().numpy().reshape((28,28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator network\n",
    "\n",
    "![GAN Network](assets/gan_network.png)\n",
    "\n",
    "Here we'll build the generator network. To make this network a universal function approximator, we'll need at least one hidden layer. We should use a leaky ReLU to allow gradients to flow backwards through the layer unimpeded. A leaky ReLU is like a normal ReLU, except that there is a small non-zero output for negative input values.\n",
    "\n",
    "\n",
    "#### Leaky ReLU\n",
    "Leaky ReLU comes with a parameter, alpha, that defines the negative slope of the function.  Use a small value, such as 0.01.\n",
    "\n",
    "\n",
    "#### Tanh Output\n",
    "The generator has been found to perform the best with $tanh$ for the generator output. This means that we'll have to rescale the MNIST images to be between -1 and 1, instead of 0 and 1.\n",
    "\n",
    ">**Exercise:** Implement the generator network in the function below. You'll need to return the tanh output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:11:04.923705Z",
     "start_time": "2020-07-29T14:11:04.915151Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z, out_dim, hidden_size=128, alpha=0.01):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ### Student code starts\n",
    "        \n",
    "        self.map1 = nn.Linear(z, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, out_dim)\n",
    "        \n",
    "        ### Student code ends\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### Student code starts\n",
    "        \n",
    "        x = self.map1(x)\n",
    "        m = nn.LeakyReLU(alpha)\n",
    "        x = m(x)\n",
    "        x = self.map2(x)\n",
    "        m = nn.Tanh()\n",
    "        out = m(x)\n",
    "        \n",
    "        ### Student code ends\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "The discriminator network is almost exactly the same as the generator network, except that we're using a sigmoid output layer.\n",
    "\n",
    ">**Exercise:** Implement the discriminator network in the function below. Same as above, you'll need to return both the logits and the sigmoid output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:11:06.631627Z",
     "start_time": "2020-07-29T14:11:06.623108Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, alpha=0.01):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        ### Student code starts\n",
    "        \n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        ### Student code ends\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### Student code starts\n",
    "        \n",
    "        x = self.map1(x)\n",
    "        m = nn.LeakyReLU(alpha)\n",
    "        x = m(x)\n",
    "        logit = self.map2(x)\n",
    "        m = nn.Sigmoid()\n",
    "        out = m(logit)\n",
    "        \n",
    "        ### Student code ends\n",
    "        \n",
    "        return logit, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:51:20.179771Z",
     "start_time": "2020-07-29T15:51:20.175165Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 784        # size of an input image (flattened)\n",
    "z_size = 100            # size of random noise vector\n",
    "g_hidden_size = 128     # size of hidden layer in generator\n",
    "d_hidden_size = 128     # size of hidden layer in discriminator\n",
    "alpha = 0.01            # leaky ReLU alpha value\n",
    "num_epochs = 100        # number of iterations\n",
    "smooth = 0.1            # label smoothing value\n",
    "learning_rate = 0.001   # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network\n",
    "\n",
    "Now we're building the network from the functions defined above.\n",
    "\n",
    "We'll create the generator, `Generator(z_size, input_size)` and additional parameters as necessary. This builds the generator with the appropriate input and output sizes.\n",
    "\n",
    "Then the discriminator, `Discriminator(input_size)` and additional parameters as necessary. \n",
    "\n",
    ">**Exercise:** Build the network from the classes you defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:51:21.924951Z",
     "start_time": "2020-07-29T15:51:21.914909Z"
    }
   },
   "outputs": [],
   "source": [
    "### Student code starts for generator and discriminator definitions\n",
    "\n",
    "g_model = Generator(z_size, input_size, hidden_size=g_hidden_size, alpha=alpha)\n",
    "\n",
    "d_model = Discriminator(input_size, hidden_size=d_hidden_size, alpha=alpha)\n",
    "\n",
    "### Student code ends\n",
    "\n",
    "g_optimizer = optim.Adam(g_model.parameters(), lr=learning_rate)\n",
    "d_optimizer = optim.Adam(d_model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Determining Discriminator and Generator Losses\n",
    "\n",
    "Now we need to calculate the losses, which is a little tricky. For the discriminator, the total loss is the average of the losses for real and fake images, `d_loss = (d_loss_real + d_loss_fake) / 2`. \n",
    "\n",
    "For the real image logits, we'll use `d_logits_real` which we got from the discriminator in the cell above. For the labels, we want them to be all ones, since these are all real images. To help the discriminator generalize better, the labels are reduced a bit from 1.0 to 0.9, for example,  using the parameter `smooth`. This is known as label smoothing, typically used with classifiers to improve performance. In PyTorch, it looks something like `labels = torch.ones_like(tensor) * (1 - smooth)`\n",
    "\n",
    "The discriminator loss for the fake data is similar. The logits are `d_logits_fake`, which we got from passing the generator output to the discriminator. These fake logits are used with labels of all zeros. Remember that we want the discriminator to output 1 for real images and 0 for fake images, so we need to set up the losses to reflect that.\n",
    "\n",
    "Finally, the generator losses are using `d_logits_fake`, the fake image logits. But, now the labels are all ones. The generator is trying to fool the discriminator, so it wants to discriminator to output ones for fake images.\n",
    "\n",
    ">**Exercise:** Train the generator and discriminator.  Calculate the losses for the discriminator and the generator. There are two discriminator losses, one for real images and one for fake images. For the real image loss, use the real logits and (smoothed) labels of ones. For the fake image loss, use the fake logits with labels of all zeros. The total discriminator loss is the sum of those two losses. Finally, the generator loss again uses the fake logits from the discriminator, but this time the labels are all ones because the generator wants to fool the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:51:23.724605Z",
     "start_time": "2020-07-29T15:51:23.709237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create 4 random vectors over -1,1.. size =100\n",
    "z_vector = 2*torch.rand(60, 100)-1 # np.random.uniform(-1, 1, size=(16, z_size))\n",
    "\n",
    "# Plot 16 images and also plot discriminator/generator loss curves...\n",
    "    \n",
    "def viz_network(epoch, dloss_curve, gloss_curve, z_vector, generator) :\n",
    "    clear_output(True)\n",
    "    \n",
    "    # Set the plot size here .. about 4units/row ()\n",
    "    plt.figure(figsize=[20,20])\n",
    "    # plt.figure().subplots_adjust(hspace=1, wspace=1)\n",
    "    \n",
    "    # First plot the loss curves and accuracy\n",
    "    ax1 = plt.subplot(5,2,1)\n",
    "    ax2 = plt.subplot(5,2,2)\n",
    "\n",
    "    ax1.plot( gloss_curve, label=\"Generator Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Generator Loss')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    #acc\n",
    "    ax2.plot( dloss_curve, label=\"Discriminator Loss\")\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Discriminator Loss')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.set_ylabel('loss')\n",
    "\n",
    "    # Now plot 4 images from the generator (same every time to see progression !)\n",
    "    gen_samples = generator(z_vector) # NCHW\n",
    "    print(gen_samples.size())\n",
    "    \n",
    "    for i in range(8):\n",
    "        axi = plt.subplot(5,2,i+3)\n",
    "        img = gen_samples[i]\n",
    "        axi.imshow(img.detach().numpy().reshape((28,28)), cmap='Greys_r')\n",
    "        axi.xaxis.set_visible(False)\n",
    "        axi.yaxis.set_visible(False)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T16:47:02.124011Z",
     "start_time": "2020-07-29T15:51:28.195030Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "gloss_curve = []\n",
    "dloss_curve = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    dloss_epoch = 0\n",
    "    gloss_epoch = 0\n",
    "    for real_images, labels in trainloader:\n",
    "        \n",
    "        # Train the generator\n",
    "        if real_images.shape[0] != batch_size:\n",
    "            break\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "        batch_z = torch.from_numpy(batch_z)\n",
    "        batch_z = batch_z.float()\n",
    "        \n",
    "        ### Student code starts to train generator\n",
    "        \n",
    "        g_fake_images = g_model(batch_z)\n",
    "        \n",
    "        d_fake_logit, d_fake_out = d_model(g_fake_images)\n",
    "        \n",
    "        one_labels = torch.ones_like(d_fake_logit) * (1 - smooth)\n",
    "        \n",
    "        g_loss = criterion(d_fake_logit, one_labels)\n",
    "        ### Student code ends\n",
    "        \n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Train the discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        real_images = real_images.view(real_images.shape[0], -1)\n",
    "        \n",
    "        ### Student code starts to train discriminator with real images\n",
    "    \n",
    "        d_real_logit, d_real_out = d_model(real_images)\n",
    "        d_real_loss = criterion(d_real_logit, one_labels)\n",
    "        \n",
    "        ### Student code starts to train discriminator with fake images\n",
    "        \n",
    "        d_fake_images = g_model(batch_z).detach()\n",
    "        d_fake_logit, d_fake_out = d_model(d_fake_images)\n",
    "        zero_labels = torch.zeros_like(d_fake_logit)\n",
    "        d_fake_loss = criterion(d_fake_logit, zero_labels)\n",
    "        \n",
    "        ### Student code starts to combine losses from training with real and fake images\n",
    "        \n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        \n",
    "        ### Student code ends\n",
    "        \n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        dloss_epoch += d_loss\n",
    "        gloss_epoch += g_loss\n",
    "        \n",
    "    # Loss Curves\n",
    "    gloss_curve.append(gloss_epoch)\n",
    "    dloss_curve.append(dloss_epoch)\n",
    "    \n",
    "    # plot intermediate results !\n",
    "    viz_network(epoch, dloss_curve, gloss_curve, z_vector, g_model) \n",
    "   \n",
    "    \n",
    "    \n",
    "    # Save several samples of generator's output after each epoch\n",
    "    # sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n",
    "    # sample_z = torch.from_numpy(z_vector).float()\n",
    "    gen_samples = g_model(z_vector)\n",
    "    samples.append(gen_samples)\n",
    "        \n",
    "    print(\"epoch\", epoch+1)\n",
    "           \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator samples from training\n",
    "\n",
    "Here we can view samples of images from the generator. \n",
    "\n",
    "Below I'm showing the generated images as the network was training, every 10 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:47:39.987464Z",
     "start_time": "2020-07-29T17:47:09.994061Z"
    }
   },
   "outputs": [],
   "source": [
    "rows, cols = 20, 16\n",
    "fig, axes = plt.subplots(figsize=(20,20), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
    "\n",
    "for sample, ax_row in zip(samples[::int(len(samples)/rows)], axes):\n",
    "    for img, ax in zip(sample[::int(len(sample)/cols)], ax_row):\n",
    "        ax.imshow(img.detach().numpy().reshape((28,28)), cmap='Greys_r')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:47:38.213880Z",
     "start_time": "2020-07-29T15:47:38.209134Z"
    }
   },
   "outputs": [],
   "source": [
    "len(samples)\n",
    "len(samples[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are samples from the final training epoch. You can see the generator is able to reproduce several fashion categories. Since this is just a sample, it isn't representative of the full range of images this generator can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples):\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.detach().numpy().reshape((28,28)), cmap='Greys_r')\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Whats next ? \n",
    "\n",
    "So how could we make this better ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
