{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cifar_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# assume yhat is [batch,10], and y is [batch,1] \n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import torch.optim as optim\n",
    "from torch.nn.init import xavier_normal_ , uniform_\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "# This is currently a CPU implemenation... \n",
    "# TODO make GPU compatible with pytorch api someday ..\n",
    "def accuracy(yhat,y) :\n",
    "    #print(yhat)\n",
    "    #print(y)\n",
    "    yhat = yhat.cpu()\n",
    "    y = y.cpu()  \n",
    "    yhat = [np.int(i.argmax()) for i in yhat]\n",
    "    yhat = np.asarray(yhat)\n",
    "    y = np.asarray(y)\n",
    "    #print(yhat.size, yhat)\n",
    "    #print(y.size,y)\n",
    "    num_correct = np.sum(np.where(y == yhat,1,0))\n",
    "    #print(\"Num Correct = {} out of {}\".format(num_correct, y.size))\n",
    "    return num_correct\n",
    "\n",
    "\n",
    "def viz_network(epoch, curves,model,use_cuda) :\n",
    "    clear_output(True)\n",
    "    \n",
    "    # Set the plot size here .. about 4units/row ()\n",
    "    plt.figure(figsize=[20,8])\n",
    "    # plt.figure().subplots_adjust(hspace=1, wspace=1)\n",
    "    \n",
    "    # First plot the loss curves and accuracy\n",
    "    ax1 = plt.subplot(2,4,1)\n",
    "    ax2 = plt.subplot(2,4,2)\n",
    "\n",
    "    for key in curves:\n",
    "        loss = [x[0] for x in curves[key]]\n",
    "        acc =  [float(x[1])/float(x[2]) for x in curves[key]]\n",
    "        #print(\"acc = {}\".format(acc))\n",
    "        #plt.scatter(range(len(curves[key])), curves[key], label=key, linewidths=1.0)\n",
    "        #loss\n",
    "        ax1.plot( loss, label=key)\n",
    "        ax1.legend()\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.set_xlabel('epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        #acc\n",
    "        ax2.plot( acc, label=key)\n",
    "        ax2.legend()\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax2.set_xlabel('epoch')\n",
    "        ax2.set_ylabel('% correct')\n",
    "    \n",
    "\n",
    "    # plot just the first convolutional layer weight distribution\n",
    "    for idx, (n,m) in enumerate(model.named_modules()):\n",
    "        if(isinstance(m,torch.nn.modules.conv.Conv2d)) :\n",
    "            #print(n,m, m.weight.size())\n",
    "            conv_weights = m.weight.detach().cpu().numpy().flatten()            \n",
    "            #print(\"epoch = {} num_cnv1w = {} cnv1w_avg = {}\".format(epoch, len(conv_weights), np.mean(conv_weights)))\n",
    "            plt.subplot(2,4,3)\n",
    "            plt.title(\"Layer {} weights\".format(n))\n",
    "            plt.hist(conv_weights)\n",
    "            \n",
    "            # Plot the gradients if available\n",
    "            plt.subplot(2,4,4)      \n",
    "            plt.title(\"Layer {} gradients\".format(n))\n",
    "            try :\n",
    "                conv_grads   =  m.weight.grad.detach().cpu().numpy().flatten()\n",
    "                print(\"epoch: {} / Conv Layer1 gradient avg :{}\".format(epoch, np.mean(conv_grads)))\n",
    "                plt.hist(conv_grads)\n",
    "            except(AttributeError) :\n",
    "                print(\"No gradients yet.  Please be patient\")\n",
    "            break;\n",
    "            \n",
    "    # plot just the first fully connected layer weight distribution\n",
    "    for idx, (n,m) in enumerate(model.named_modules()):\n",
    "        if(isinstance(m,torch.nn.modules.linear.Linear)) :\n",
    "            # print(m, m.weight.size())\n",
    "            fc_weights = m.weight.detach().cpu().numpy().flatten()\n",
    "            #print(\"epoch = {} num_fc1w = {} fc1w_avg = {}\".format(epoch, len(fc_weights), np.mean(fc_weights)))\n",
    "            plt.subplot(2,4,5)\n",
    "            plt.title(\"Layer {} weights\".format(n))\n",
    "            plt.hist(fc_weights)\n",
    "            # Plot the gradients if available\n",
    "            plt.subplot(2,4,6)            \n",
    "            plt.title(\"Layer {} gradients\".format(n))\n",
    "            try :\n",
    "                fc_grads   =  m.weight.grad.detach().cpu().numpy().flatten()\n",
    "                print(\"epoch: {} / Fully Connected Grad avg : {}\".format(epoch, np.mean(fc_grads)))\n",
    "                plt.hist(fc_grads)\n",
    "            except(AttributeError) :\n",
    "                print(\"No gradients yet.  Please be patient\")\n",
    "            \n",
    "\n",
    "            break;\n",
    "\n",
    "    plt.show()\n",
    "       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
