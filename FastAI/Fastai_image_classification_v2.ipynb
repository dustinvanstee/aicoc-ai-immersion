{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your custom image classifier using FastAI and OPEN-CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook was copied and modified for this lab from this source https://github.com/fastai/course-v3*\n",
    "\n",
    "\n",
    "\n",
    "Welcome to TechU Deep Learning Lab! \n",
    "\n",
    "For those of you who are using a Jupyter Notebook for the first time, you can learn about this useful tool in a tutorial we prepared specially for you; click `File`->`Open` now and click `jupyter_notebook_tutorial.ipynb`. [./jupyter_notebook_tutorial.ipynb](./jupyter_notebook_tutorial.ipynb)\n",
    "\n",
    "In this lesson we will **build our first image classifier from scratch**, and see if we can achieve world-class results. Let's dive in!\n",
    "\n",
    "Note, the most recent version of this lab is now using a build from OpenCE .  We have PyTorch 1.6 running with Fastai-version 2.  For more information about how to build the most recent deep learning frameworks for Power check out this repo.\n",
    "\n",
    "https://github.com/open-ce/open-ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:16:59.474116Z",
     "start_time": "2020-08-04T13:16:59.180693Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "# For Using GPU's\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About our Class Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import all the necessary packages. We are going to work with the [fastai V2 library](http://www.fast.ai/) which sits on top of [Pytorch 1.6](https://pytorch.org/). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.\n",
    "\n",
    "For this class, we are using Open-CE running in the **IBM Garage for Systems Cloud**, or CECC for short.  To get your own environment, simply browse to this website and request a Power8 or Power9 environment.\n",
    "\n",
    "https://www.ibm.com/it-infrastructure/services/cecc-portal/web/Catalog\n",
    "\n",
    "* Note : To get FastAI up and running we have a special setup script in our github repo ... \n",
    "\n",
    "https://github.ibm.com/vanstee/aicoc-ai-immersion/blob/master/FastAI/setup_fastai.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import FastAI Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:04.679391Z",
     "start_time": "2020-08-04T13:17:03.139740Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# utility print function\n",
    "def nprint(mystring) :\n",
    "    print(\"**{}** : {}\".format(sys._getframe(1).f_code.co_name,mystring))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Configuration\n",
    "\n",
    "This data structure below will hold all the settings for our class.  Its handy to have a simple dictionary contain all your project settings to keep organized.  We have include an override capability to these default settings so that you can customize your project. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:04.891443Z",
     "start_time": "2020-08-04T13:17:04.846010Z"
    }
   },
   "outputs": [],
   "source": [
    "def getconfig(cfg_in={},base_dir=\".\"):\n",
    "    cfg = {}\n",
    "    cfg[\"bs\"] = 16\n",
    "    cfg[\"base_dir\"]  = base_dir\n",
    "    cfg[\"image_dir\"] = base_dir + \"/class_images\"\n",
    "    cfg[\"classes\"] = [\"cars\",\"busses\",\"trucks\"]\n",
    "    cfg[\"num_images\"] = {\"train\":200,\"valid\":0,\"test\":0}  # only use train for class. FastAI will autosplit\n",
    "    cfg[\"d_partitions\"] = list(cfg[\"num_images\"].keys())                 \n",
    "    cfg[\"jpeginfo\"] =base_dir + \"/jpeginfo\"\n",
    "   \n",
    "    # overwrite configs if passed\n",
    "    for (k,v) in cfg_in.items() :\n",
    "        nprint(\"Overriding Config {}:{} with {}\".format(k,cfg[k],v))\n",
    "        cfg[k] = v\n",
    "    return cfg\n",
    "\n",
    "# bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Dataset on the Fly .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to build our own dataset !!  Think of 3 categories you would like to classify images.  In this example, we will use \n",
    "* people playing sports\n",
    "* people holding money \n",
    "* people holding cups\n",
    "* people playing with animals\n",
    "* people on bikes\n",
    "\n",
    "We will use an open source tool called **googliser** [https://github.com/teracow/googliser](https://github.com/teracow/googliser) to download our images from google images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:07.211661Z",
     "start_time": "2020-08-04T13:17:07.157172Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "# @@ Students : Customize this cell with your custom classes for image classification\n",
    "################################################################################################\n",
    "\n",
    "# Overrides for lab\n",
    "\n",
    "mycfg = {\n",
    "     ## CLASS Enter your search terms below \n",
    "    \"classes\"     : [\"people playing sports\",\n",
    "                     \"people holding money\",\n",
    "                     \"people holding cups\",\n",
    "                     \"people playing with animals\",\n",
    "                     \"people on bikes\"], \n",
    "    \"d_partitions\": [\"train\"],\n",
    "    \"num_images\"  : {\"train\":300,\"valid\":0,\"test\":0}  # only use train for class. FastAI will autosplit\n",
    "  \n",
    "}\n",
    "\n",
    "# Setup Class Configuration\n",
    "# base_dir=!pwd\n",
    "# base_dir=base_dir[0]\n",
    "base_dir = \"/home/cecuser/5050/aicoc-ai-immersion/FastAI\"\n",
    "print(\"Base project directory : {}\".format(base_dir))\n",
    "cfg=getconfig(mycfg, base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Some Directories to hold our data \n",
    "\n",
    "FastAI is very flexible and help you label your image data in all sorts of ways.  The most stand  \n",
    "\n",
    "You might have a bunch of images and a csv file with the labels.  You might have your images organized by folder with the folder name being the labels.  FastAI provid\n",
    "\n",
    "To see all the supported methods check out this link..\n",
    "https://docs.fast.ai/vision.data.html#ImageDataBunch.from_folder\n",
    "\n",
    "For our class, we are going to organize our data by folder into something like this.. \n",
    "```\n",
    "base/class_images/train\n",
    "   people_holding_cups    people_on_bikes          people_playing_with_animals  \n",
    "   people_holding_money   people_playing_sports           \n",
    "```\n",
    "\n",
    "In each folder we will have a bunch of \\*.jpg files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Directory Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helpers to make directories\n",
    "def class_folder_name(base,d_part,cls) :\n",
    "    return base+\"/\"+d_part+\"/\"+ cls.replace(\" \",\"_\")\n",
    "\n",
    "def makeDirIfNotExist(directory) :\n",
    "    if not os.path.exists(directory):  \n",
    "        nprint(\"Making directory {}\".format(directory))\n",
    "        os.makedirs(directory) \n",
    "    else :\n",
    "        nprint(\"Directory {} already exists .. \".format(directory))\n",
    "\n",
    "# Build directory hierarchy\n",
    "#   [train|valid|test ]\n",
    "#    -----------------> [class1 | class2 | class...]\n",
    "#for d_part in cfg[\"d_partitions\"] :\n",
    "#    for cls in cfg[\"classes\"] :\n",
    "#        directory=class_folder_name(cfg['image_dir'],d_part,cls)\n",
    "#        makeDirIfNotExist(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Googliser here.  \n",
    "This handy utility will download our images from google images.  We will clone the repo from git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:09.449332Z",
     "start_time": "2020-08-04T13:17:09.263617Z"
    }
   },
   "outputs": [],
   "source": [
    "# install googliser\n",
    "def install_googliser():\n",
    "    googliser_directory = cfg['base_dir']+\"/googliser\"\n",
    "    if not os.path.exists(googliser_directory):  \n",
    "        nprint(\"Installing Googliser here : {} \".format(googliser_directory))\n",
    "        os.chdir(cfg['base_dir'])\n",
    "        !git clone https://github.com/teracow/googliser\n",
    "    else :\n",
    "        nprint(\"Googliser already installed here : {} \".format(googliser_directory))\n",
    "\n",
    "    googliser = cfg['base_dir']+\"/googliser/googliser.sh\"\n",
    "\n",
    "    return googliser \n",
    "googliser = install_googliser()\n",
    "!ls {googliser}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many images should we grab ?\n",
    "\n",
    "\n",
    "Luckily not too many.. it always depends on the project, but we are going to use a pre-training deep learning network when we perform training.  Since that network was already trained on over 1 million images, we don't need to supply too many for our task.  This is why transfer learning is so powerful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:10.321357Z",
     "start_time": "2020-08-04T13:17:10.279274Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg['num_images']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask to the rescue!\n",
    "Here we use python dask to download many images in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:41.679531Z",
     "start_time": "2020-08-04T13:17:10.975958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The code below will download files to train folder only to avoid duplicate downloads.  \n",
    "# We then move a few files over.  This can be done manually or programatically.  For our example\n",
    "# we will let FastAI do the work for us!\n",
    "def runcmd(cmd):\n",
    "    !{cmd}\n",
    "    return 1;\n",
    "\n",
    "def download_images(cfg, force_download=False):\n",
    "    # Download if directory does not exist or Force download = True\n",
    "    results=[]\n",
    "    \n",
    "    if(not(os.path.exists(cfg['image_dir']))) :\n",
    "       nprint(\"Image directory {} does not exist.  Downloading images..\".format(cfg['image_dir']))\n",
    "       force_download = True\n",
    "    else :\n",
    "        nprint(\"image dir exists : {}.  Not downloading again.  \\nuse force_download=True to overwrite\".format(cfg['image_dir']))\n",
    "    \n",
    "    if(force_download) :\n",
    "        utility_dir = cfg['base_dir']\n",
    "        for d_p in cfg[\"d_partitions\"] : # train only for now ..\n",
    "            for cls in cfg[\"classes\"] :\n",
    "                directory=class_folder_name(cfg['image_dir'],d_p,cls)\n",
    "                makeDirIfNotExist(directory)\n",
    "\n",
    "                current_dir =class_folder_name(cfg['image_dir'],d_p,cls)\n",
    "                #os.chdir(current_dir)\n",
    "                os.chdir(utility_dir)\n",
    "                command = googliser + \\\n",
    "                          \" --o {}\".format(current_dir) +\\\n",
    "                          \" --phrase \\\"{}\\\"\".format(cls) + \\\n",
    "                          \" --parallel 50 --upper-size 1000000 --lower-size 2000 \" + \\\n",
    "                          \" -n {}\".format(cfg['num_images'][d_p]) + \\\n",
    "                          \" --format jpg --timeout 15 --safesearch-off \"\n",
    "                nprint(command)\n",
    "                results.append(delayed(runcmd)(command))\n",
    "        results=sum(results)\n",
    "        \n",
    "        print(results.compute())\n",
    "        nprint(\"Downloads complete!\")\n",
    "       \n",
    "download_images(cfg,force_download=True)\n",
    "\n",
    "# This will take ~5 mins depending on how many classes / images we are grabbing... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up downloaded images that are not proper jpeg format .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:45.687243Z",
     "start_time": "2020-08-04T13:17:41.848978Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean with jpeginfo! \n",
    "def clean_up_bad_images(cfg):\n",
    "    os.chdir(cfg['image_dir'])\n",
    "    nprint(\"Search for Error files in {}......\".format(cfg['image_dir']))\n",
    "    # handle both jpg //jpeg files that are malformed\n",
    "    for ext in [\"jpg\",\"jpeg\"] :\n",
    "        command = \"find . -name \\\"*.{}\\\"\".format(ext) + \\\n",
    "          \" | xargs -i {}\".format(cfg[\"jpeginfo\"]) + \\\n",
    "          \" -c {} | grep ERROR\"\n",
    "        nprint(\"Running command : {}\".format(command))\n",
    "        !{command}\n",
    "        nprint(\"Removing any error files listed above\")\n",
    "        command = command + ' | cut -d \" \" -f1 | xargs -i rm {} '\n",
    "        nprint(\"Running command : {}\".format(command))\n",
    "        !{command}\n",
    "        nprint(\"Done\")\n",
    "    # get rid of png /webp\n",
    "    for ext in [\"png\", \"webp\"]:\n",
    "        command = \"find . -name \\\"*.{}\\\"\".format(ext) + \\\n",
    "            \" | xargs -i rm -f {}\"\n",
    "        nprint(\"Running command : {}\".format(command))\n",
    "        !{command}\n",
    "        \n",
    "clean_up_bad_images(cfg)\n",
    "\n",
    "# find . -name \"*.jpg,\" | xargs -i ./jpeginfo -c {}\n",
    "# find . -name \"*.jpg\" | xargs -i ./jpeginfo -c {} | grep ERROR | cut -d \" \" -f1 | xargs -i rm {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:45.896085Z",
     "start_time": "2020-08-04T13:17:45.857059Z"
    }
   },
   "outputs": [],
   "source": [
    "#path = untar_data(URLs.PETS); path\n",
    "path = Path(cfg['image_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:46.104862Z",
     "start_time": "2020-08-04T13:17:46.064663Z"
    }
   },
   "outputs": [],
   "source": [
    "path.ls()\n",
    "#cfg['image_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do when we approach a problem is to take a look at the data. We _always_ need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Taking a look at the data means understanding how the data directories are structured, what the labels are and what some sample images look like.\n",
    "\n",
    "The main difference between the handling of image classification datasets is the way labels are stored. In this particular dataset, **labels are stored in the name of the folder containing the file**. We will need to extract them to be able to classify the images into the correct categories. Fortunately, the fastai library has a handy function made exactly for this, `ImageDataLoaders.from_folder` gets the labels from the folder name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets / Dataloaders\n",
    "Fastai has a number of methods to create a \n",
    "\n",
    "Datasets and Dataloaders (notice the 's' on the class names) are FastAI abstractions to help us load and process the image data.  In general these classes support all sorts of datatype like image / tabular/ and text.  \n",
    "\n",
    "The main goal of Datasets / Dataloaders is to help hold all the data (train / validataion / test) in a single data structure and also allow us to easily transform and create batches for training.  \n",
    "\n",
    "The creation of datasets / dataloaders is based on using something called the datablock API.  This is a set of tools to help you build out instances of the datasets/dataloaders classes.\n",
    "\n",
    "For a full treatment of dataloaders / datasets/ datablock API topic see the documenation here -> https://docs.fast.ai/tutorial.datablock\n",
    "\n",
    "This notebook was built referencing the documentation link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAI makes use of the python Pathlib library.  here are a couple examples of how this works.\n",
    "\n",
    "# get_image_files is a FastAI utility to grab all images from a provided base path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:17:46.336815Z",
     "start_time": "2020-08-04T13:17:46.271780Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastai.data.all as fda\n",
    "import fastai.vision.all as fva\n",
    "\n",
    "fnames = fda.get_image_files(path)\n",
    "\n",
    "# Some Path Experiments\n",
    "# This will be useful for our label func ..\n",
    "# https://docs.python.org/3/library/pathlib.html\n",
    "fname = fnames[0]\n",
    "print(type(fname))\n",
    "print(fname)\n",
    "print(\"Name : {}\".format(fname.name))\n",
    "print(\"Parent : {}\".format(fname.parent))\n",
    "print(\"Suffix : {}\".format(fname.suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1 use DataBlock API\n",
    "# References\n",
    "# https://docs.fast.ai/tutorial.datablock\n",
    "# https://docs.fast.ai/data.transforms#RandomSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create our own label function to grab the name of the folder that holds the label.\n",
    "def label_func(fname):\n",
    "    # this returns the name of the folder the file is in.  This is the label!\n",
    "    return str(fname.parent).split('/')[-1]\n",
    "\n",
    "# Example\n",
    "print(\"Full file name  : {}\".format(fname))\n",
    "print(\"Label extracted : {}\".format(label_func(fname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug+transforms \n",
    "# https://docs.fast.ai/vision.augment#aug_transforms\n",
    "dblockv1 = fda.DataBlock(blocks    = (fva.ImageBlock, fda.CategoryBlock), # Tell datablock api we have images / categories\n",
    "                   get_items = fda.get_image_files, # this recurses the datablock directory that is provided\n",
    "                   get_y     = label_func, # applies the label\n",
    "                   splitter  = fda.RandomSplitter(), # splitting func\n",
    "                   item_tfms = fva.Resize(400),\n",
    "                   batch_tfms=[*fva.aug_transforms(size=224, min_scale=0.85), fva.Normalize.from_stats(*fva.imagenet_stats)])\n",
    "\n",
    "\n",
    "dsets_v1 = dblockv1.datasets(path)\n",
    "print(\"Example X,y : {}\".format(dsets_v1.train[0]))\n",
    "print(\"labels in this dataset : {}\".format(dsets_v1.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of images ...\n",
    "bs=64\n",
    "dls = dblockv1.dataloaders(path,bs=bs)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblockv1.summary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Method using FastAI built-in ImageDataLoaders [use above for class]\n",
    "# bs = 64\n",
    "# \n",
    "# # https://docs.fast.ai/vision.data#ImageDataLoaders.from_folder\n",
    "# dlsv2 = ImageDataLoaders.from_folder(\n",
    "#     path, \n",
    "#     item_tfms=Resize(460), \n",
    "#     bs=bs,\n",
    "#     valid_pct=0.20,\n",
    "#     batch_tfms=[*aug_transforms(max_lighting=0.5, size=224, min_scale=0.65), Normalize.from_stats(*imagenet_stats)])\n",
    "# dlsv2.show_batch(max_n=9, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Traing set vs Validation set Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_label_distribution(dls) :\n",
    "    # *dls.xxx_ds returns tuples split into parts..zip reassembles into x/y vectors ...\n",
    "    x,y = zip(*dls.train_ds)\n",
    "    xv,yv = zip(*dls.valid_ds)\n",
    "    \n",
    "    # this creates our labels list.  basically transform fastai.tensor object to a simple list of ints \n",
    "    y_labels = list(map(lambda a : a.item() ,y))\n",
    "    yv_labels = list(map(lambda a : a.item() ,yv))\n",
    "    \n",
    "    # Create a dataframe of categorical counts\n",
    "    df=pd.DataFrame([\n",
    "        pd.Series(y_labels).value_counts(),\n",
    "        pd.Series(yv_labels).value_counts()\n",
    "       ]).T\n",
    "    # Add percentages..\n",
    "    df.columns = [\"train\",\"valid\"]\n",
    "    df[\"train_pct\"] = df[\"train\"]/df[\"train\"].sum()\n",
    "    df[\"valid_pct\"] = df[\"valid\"]/df[\"valid\"].sum()\n",
    "    df[\"labels\"] = pd.Series(dls.vocab)\n",
    "    display(df)\n",
    "    # If you did want to plot, look at this\n",
    "    # https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/categorical_variables.html\n",
    "\n",
    "type(dls.train_ds)\n",
    "type(dls.valid_ds)\n",
    "\n",
    "print(\"Num Images in Training Set : {}\".format(len(dls.train_ds)))\n",
    "print(\"Num Images in Validation Set : {}\".format(len(dls.valid_ds)))\n",
    "\n",
    "get_label_distribution(dls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis .. \n",
    "Make sure prior to the run you are ok with the class balance in the test vs validation.  Class imbalance between these 2 sets are important for good results.  I like to look for 2 things\n",
    "\n",
    "1. Each class has a similar number of images ..\n",
    "2. The percentage of images in training for a certain class = percentage of images for the validation .. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using Transfer Learning : resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start training our model. We will use a [convolutional neural network](http://cs231n.github.io/convolutional-networks/) backbone and a fully connected head with a single hidden layer as a classifier. Don't know what these things mean? \n",
    "\n",
    "Not to worry, check out the FastAI course videos for a deep dive [https://course.fast.ai/](https://course.fast.ai/). For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories (in this case, it will have 5 outputs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:18:01.421297Z",
     "start_time": "2020-08-04T13:17:59.657302Z"
    }
   },
   "outputs": [],
   "source": [
    "#create learner\n",
    "learn = fva.cnn_learner(dls, fva.resnet34, metrics=error_rate).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:18:04.158307Z",
     "start_time": "2020-08-04T13:18:04.111751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets see a summary of the model\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:18:57.712758Z",
     "start_time": "2020-08-04T13:18:06.880917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets Train a little to see where we stand. \n",
    "# Fit_one_cycle uses cyclical learning rates\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:19:01.984573Z",
     "start_time": "2020-08-04T13:19:01.426257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets run lr_find to find the optimal learning rates\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:19:48.201773Z",
     "start_time": "2020-08-04T13:19:05.416555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run 5 epochs (can do more if still getting better train / val)\n",
    "# FILL IN THE RANGE BASE ON YOUR LRFIND RESULT\n",
    "learn.fit_one_cycle(5, max_lr=slice(8e-4,2e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out our current results ..\n",
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what results we have got. \n",
    "\n",
    "We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. \n",
    "\n",
    "Furthermore, when we plot the confusion matrix, if we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:19:53.528751Z",
     "start_time": "2020-08-04T13:19:51.574146Z"
    }
   },
   "outputs": [],
   "source": [
    "interp = fva.ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "len(dls.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:19:57.146846Z",
     "start_time": "2020-08-04T13:19:57.061684Z"
    }
   },
   "outputs": [],
   "source": [
    "fda.doc(interp.plot_top_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:20:03.218521Z",
     "start_time": "2020-08-04T13:20:00.831206Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(19,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:20:07.112619Z",
     "start_time": "2020-08-04T13:20:06.802587Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
    "interp.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:20:10.418900Z",
     "start_time": "2020-08-04T13:20:10.366039Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreezing, fine-tuning, and learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model is working as we expect it to, we will *unfreeze* our model and train some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:20:14.303316Z",
     "start_time": "2020-08-04T13:20:14.023677Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:20:59.823066Z",
     "start_time": "2020-08-04T13:20:17.946256Z"
    }
   },
   "outputs": [],
   "source": [
    "#learn.fit_one_cycle(8)\n",
    "learn.fit_one_cycle(5, max_lr=slice(8e-4,2e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:21:03.422164Z",
     "start_time": "2020-08-04T13:21:03.375876Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('stage-2')\n",
    "#learn.load('stage-1');\n",
    "#learn.unfreeze(-2)\n",
    "#learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:21:09.296710Z",
     "start_time": "2020-08-04T13:21:07.080257Z"
    }
   },
   "outputs": [],
   "source": [
    "interp = fva.ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "len(dls.valid_ds)==len(losses)==len(idxs)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty accurate model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optional Assignment Training: xresnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. The details in the [resnet paper](https://arxiv.org/pdf/1512.03385.pdf) and this post https://towardsdatascience.com/xresnet-from-scratch-in-pytorch-e64e309af722.\n",
    "\n",
    "Basically, xresnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. Recommendations \n",
    "* let's us use larger images too, \n",
    "* reduce the batch size a bit since otherwise this larger network will require more GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you redo the training above with a different pre-trained model ???  See this page for some ideas\n",
    "\n",
    "https://docs.fast.ai/vision.models.xresnet\n",
    "\n",
    "copy the above code below, or maybe make a copy of your notebook and try it out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:24:42.217520Z",
     "start_time": "2020-08-04T13:24:40.018767Z"
    }
   },
   "outputs": [],
   "source": [
    "# example !\n",
    "learn = fva.cnn_learner(dls, fva.xresnet50, metrics=error_rate).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:24:45.760752Z",
     "start_time": "2020-08-04T13:24:45.704802Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Example :  Integration with Maximo Visual Insights\n",
    "\n",
    "So you want to train on some data that maybe you labelled in another tool ?  No problem.  Here we show how to read in data exported from Maximo Visual Insights and classify using FastAI.\n",
    "\n",
    "For our IBM Maximo Visual Insights Example, we can just run a nice utility to reformat the output.  For convenience, we added a **Bananas Dataset** to our repo to play with .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:25:22.384596Z",
     "start_time": "2020-08-04T13:25:22.195071Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(cfg[\"base_dir\"])\n",
    "!ls *.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip our bananas data and convert to images in sub-directories\n",
    "\n",
    "When you export data from IVI, you get a single zip file.  When you unzip this file, you get a singular directory with a metadata file called prop.json.  We have a utility that will read that prop.json and create a new directory with sorted images... lets see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:08.726921Z",
     "start_time": "2020-08-04T13:28:08.514648Z"
    }
   },
   "outputs": [],
   "source": [
    "# unzip the Bananas.zip to /tmp/bananas_ivi directory\n",
    "!sudo yum install -y unzip\n",
    "!unzip -o -d /tmp Bananas.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:12.550268Z",
     "start_time": "2020-08-04T13:28:12.362584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now download our handy Maximo dataset conversion script !\n",
    "# Maximo Visual Insights exports data in a unique format with image files\n",
    "# and a json file containing label metadata.  Our script reads this in\n",
    "# and converts that into a nice directory structure with the folder\n",
    "# containing the class label\n",
    "!git clone https://github.com/dustinvanstee/powerai-vision-utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:19.541526Z",
     "start_time": "2020-08-04T13:28:17.574019Z"
    }
   },
   "outputs": [],
   "source": [
    "#!conda install -y scikit-learn # dependency to run our utility ..\n",
    "!python powerai-vision-utils/reorganize_exported_dataset.py --directory_in /tmp/Bananas --directory_out /tmp/bananas_fastai/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:24.226618Z",
     "start_time": "2020-08-04T13:28:24.040548Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /tmp/bananas_fastai/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:27.432401Z",
     "start_time": "2020-08-04T13:28:27.386095Z"
    }
   },
   "outputs": [],
   "source": [
    "# New project config!\n",
    "mycfg = {\n",
    "    \"image_dir\" : \"/tmp/bananas_fastai\",\n",
    "    \"classes\":[\"black\",\"green\",\"overripe\",\"yellow\",\"ripe\"],  ## <<- CLASS Enter your search terms here \n",
    "    \"d_partitions\":[\"train\"],\n",
    "}\n",
    "ivicfg=getconfig(mycfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:30.212749Z",
     "start_time": "2020-08-04T13:28:30.168072Z"
    }
   },
   "outputs": [],
   "source": [
    "# New Image Path ..\n",
    "path = Path(ivicfg[\"image_dir\"])\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:29:04.142881Z",
     "start_time": "2020-08-04T13:29:03.957149Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /tmp/bananas_fastai/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:29:08.501254Z",
     "start_time": "2020-08-04T13:29:07.634703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define some transforms and setup data bunch\n",
    "#tfms = get_transforms(do_flip=True)\n",
    "#data = ImageDataBunch.from_folder(path,train=\"train\", ds_tfms=tfms, size=100, valid_pct=0.20)\n",
    "#data\n",
    "\n",
    "#Alternative Method using FastAI built-in ImageDataLoaders [use above for class]\n",
    "bs = 64\n",
    "# \n",
    "# # https://docs.fast.ai/vision.data#ImageDataLoaders.from_folder\n",
    "dls = fva.ImageDataLoaders.from_folder(\n",
    "    path, \n",
    "    item_tfms=fva.Resize(460), \n",
    "    bs=bs,\n",
    "    valid_pct=0.33,\n",
    "    batch_tfms=[*fva.aug_transforms(max_lighting=0.5, size=224, min_scale=0.65), fva.Normalize.from_stats(*fva.imagenet_stats)])\n",
    "dls.show_batch(max_n=9, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_distribution(dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:29:40.956727Z",
     "start_time": "2020-08-04T13:29:20.834597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup a CNN learner\n",
    "learn = fva.cnn_learner(dls, fva.resnet50, metrics=fva.accuracy)\n",
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:31:36.745706Z",
     "start_time": "2020-08-04T13:29:43.402740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Learning rate search\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:00:52.922945Z",
     "start_time": "2020-08-04T14:00:44.318769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run fit one cycle for 5 epochs\n",
    "learn.fit_one_cycle(5,slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:03.723211Z",
     "start_time": "2020-08-04T13:25:36.540Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5,slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:03.727734Z",
     "start_time": "2020-08-04T13:25:37.002Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:28:03.732229Z",
     "start_time": "2020-08-04T13:25:37.529Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5,slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:12:47.617123Z",
     "start_time": "2020-08-04T13:08:46.977Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1,slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:00:54.448867Z",
     "start_time": "2020-08-04T14:00:53.709502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets see how well we did ... \n",
    "interp = fva.ClassificationInterpretation.from_learner(learn)\n",
    "losses,idxs = interp.top_losses()\n",
    "len(dls.valid_ds)==len(losses)==len(idxs)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:01:07.676727Z",
     "start_time": "2020-08-04T14:01:03.542887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download some sample images here .... \n",
    "command = googliser + \\\n",
    "                      \" --o /tmp/banana_inference \"+\\\n",
    "                      \" --phrase \\\"ripe black yellow green bananas\\\" \" + \\\n",
    "                      \" --parallel 50 --upper-size 500000 --lower-size 2000 \" + \\\n",
    "                      \" -n 10 \" + \\\n",
    "                      \" --format jpg --timeout 15 --safesearch-off \"\n",
    "print(command)\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:01:08.637854Z",
     "start_time": "2020-08-04T14:01:08.438407Z"
    }
   },
   "outputs": [],
   "source": [
    "# get rid of malformed images manually .\n",
    "\n",
    "command = cfg[\"jpeginfo\"] + \" -c /tmp/banana_inference\"\n",
    "!{command}\n",
    "\n",
    "#!ls /tmp/banana_inference\n",
    "#!rm /tmp/banana_inference/image\\(0020\\).jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:01:12.117669Z",
     "start_time": "2020-08-04T14:01:09.266037Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inference on your list of images .. \n",
    "import glob\n",
    "import PIL\n",
    "from IPython.display import Image \n",
    "\n",
    "files = glob.glob(\"/tmp/banana_inference/image*.jpg\")\n",
    "\n",
    "def single_inference(img_path) :\n",
    "    \n",
    "    # img = open_image(img_path)\n",
    "    #img = PIL.Image.open(img_path)\n",
    "    prediction=learn.predict(img_path)\n",
    "    print(prediction)\n",
    "    #img_cls = data.classes[prediction[1].numpy()]\n",
    "    #img.show(title=img_cls)\n",
    "    pil_img = Image(filename=img_path)\n",
    "    display(pil_img)\n",
    "\n",
    "for my_img in files :\n",
    "    single_inference(Path(my_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you can now build a pretty darn good classifier in less than one hour!\n",
    "\n",
    "Credits \n",
    "* FastAI Team\n",
    "* Bob Chesebrough / Dustin VanStee / Clarisse Taffe-Hedglin - AICoC Data science team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
