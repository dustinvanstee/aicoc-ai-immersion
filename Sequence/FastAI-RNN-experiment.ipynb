{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "https://medium.com/analytics-vidhya/finding-data-block-nirvana-a-journey-through-the-fastai-data-block-api-part-2-9b23ea5d83ee\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data set ....\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.init import xavier_normal_ , uniform_\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import fastai\n",
    "from fastai.data_block import FloatList\n",
    "from fastai.basic_train import *\n",
    "from fastai.metrics import *\n",
    "import random; \n",
    "\n",
    "import os\n",
    "\n",
    "def model_summary(net) :\n",
    "    #print(net.children)\n",
    "    header = \"{:<30}{:<30}{:<20}\".format(\"Layer\" ,\"Weight Size\", \"#Params\")\n",
    "    print(header)\n",
    "    print(\"=\"*70)\n",
    "    tp = 0\n",
    "    for (ln,i) in net.named_parameters() :\n",
    "        #print(ln, i.size(),np.prod(np.asarray(i.size())))\n",
    "        trainable_params = np.prod(np.asarray(i.size()))\n",
    "        ln_out = \"{:<30}{:<30}{:<20}\".format(ln , str(i.size()), trainable_params)\n",
    "        print(ln_out)\n",
    "        tp += trainable_params\n",
    "    print(\"=\"*70)\n",
    "    print(\"Total params: {}\".format(tp))\n",
    "\n",
    "def set_device(MODE,num=0) :\n",
    "#MODE = \"GPU\" # CPU\n",
    "    device=None\n",
    "    if(MODE==\"GPU\") :\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(num)\n",
    "        print('CUDA available: {}  Using device {}'.format(torch.cuda.is_available(), os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        device = torch.device('cuda')\n",
    "    else :\n",
    "        device = torch.device('cpu')\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = set_device(\"GPU\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Synthetic DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_set(NP=1000,p=0.05) :\n",
    "    # Create a sample time series\n",
    "    x_range = int(NP/10) # basically a point every 0.1 in x ..\n",
    "    print(\"Creating Dataset : Num Points = {} Reset prob = {}\".format(NP,p))\n",
    "    print(\"Sine wave with {} samples over x range of {}\".format(NP,x_range))\n",
    "    ii=np.linspace(0,x_range,num=NP)\n",
    "    a = np.sin(ii)\n",
    "    b = np.random.choice([0,1],size=NP,p=[p,1-p])\n",
    "    b2 = np.zeros(NP)\n",
    "    c = np.zeros(NP)\n",
    "    idx=0\n",
    "    for i in range(NP) :\n",
    "        if(b[i]==0 or i==0):\n",
    "            idx=0\n",
    "            b[i]=0\n",
    "        c[i] = a[idx]\n",
    "        b2[i] = idx\n",
    "        idx+=1\n",
    "    c_prev = np.zeros(NP)\n",
    "    c_prev[1:NP] = c[0:NP-1]\n",
    "    \n",
    "    X = np.stack((a,b,b2,c_prev),axis=1)\n",
    "    y = c\n",
    "    columns=['ii','a','b','b2','c_prev','c']\n",
    "    return(ii,X,y,columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    # y_offset is cycles into future\n",
    "    def __init__(self,NP,Tx=70,y_offset=0,num_features=1):\n",
    "        ii,x,y,columns = create_data_set(NP=NP)\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.columns=columns\n",
    "        self.NP=NP\n",
    "        self.Tx=Tx\n",
    "        self.y_offset=y_offset\n",
    "        self.num_features=num_features\n",
    "        if(num_features == 1) : print(\"Warning only returning one feature (reset).\\n  Hack around with CustomDataset to get what you want\")\n",
    "        elif(num_features == 2) : print(\"Warning only returning two features (reset and counter)\\n.  Hack around with CustomDataset to get what you want\")\n",
    "        elif(num_features == 2) : print(\"Warning only returning 4 features (orig_sin, reset and counter, prev)\\n.  Hack around with CustomDataset to get what you want\")\n",
    "        else : print(\"Warning , verify what you want and add some code here\")\n",
    "        self.c=Tx # fastai requirment\n",
    "        self.loss_func=nn.MSELoss()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    # this returns numpy arrays ....\n",
    "    def __getitem__(self, idx):\n",
    "        # simple fix to going out of bounds\n",
    "        if(idx > NP-self.Tx - 1) :\n",
    "            idx -= self.Tx\n",
    "        X=self.x[idx:idx+self.Tx]\n",
    "        y=self.y[idx+self.y_offset:idx+self.Tx+self.y_offset]\n",
    "        if(len(X) < self.Tx) :\n",
    "            print(\"error idx = {}\".format(idx))\n",
    "        if(self.num_features == 1) : # just return the 'reset signal'\n",
    "            X=X[:,1:2]\n",
    "        elif(self.num_features == 2) :\n",
    "            X=X[:,1:3]\n",
    "        elif(self.num_features == 4) :\n",
    "            # do nuttin\n",
    "            X=X\n",
    "        \n",
    "        X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "        y = torch.from_numpy(y).type(torch.FloatTensor)\n",
    "        return X,y\n",
    "\n",
    "# Custom Collate function to take a set of tuples (Seqlen x numfeatures) and convert to\n",
    "# (Seqlen x batch x numfeatures)\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (X, y)\n",
    "\n",
    "    \"\"\"\n",
    "    # collate X, y\n",
    "    X, y  = zip(*data)\n",
    "    X=torch.stack( X, axis=1 )\n",
    "    y=torch.stack( y, axis=1 )\n",
    "    \n",
    "    #print(len(X),type(X),X.size())\n",
    "    #print(len(y),type(y),y.size())\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"np.sin is in radians\")\n",
    "NP=10000\n",
    "dataset = CustomDataset(NP=NP,Tx=70,num_features=4)\n",
    "(x0,y0) = dataset[0]\n",
    "dl = DataLoader(dataset, collate_fn=collate_fn, batch_size=6,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100) :\n",
    "    (X,y) = next(iter(dl))\n",
    "    type(X)\n",
    "#print(X.size())\n",
    "X.to(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X:,0 is a... just a sine wave ...\n",
    "# resets when b equals zero\n",
    "plt.figure(figsize=(25,5))\n",
    "display(plt.plot(x0[:,0],'-bo',markersize=5))\n",
    "display(plt.plot(x0[:,1],'-bo',markersize=5))\n",
    "\n",
    "display(plt.plot(y0,'-go',markersize=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuck it in a DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x0.shape)\n",
    "print(y0.shape)\n",
    "df=pd.DataFrame(x0, columns=['a','b','b2','c_prev'])\n",
    "df[\"y\"] = y0\n",
    "\n",
    "df.head(20) # 2*pi 6.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Using pytorch RNN library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with Xavier normal distribuition        \n",
    "def weights_xavier(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier_normal_(m.weight.data)\n",
    "    elif isinstance(m, nn.Linear) :\n",
    "        xavier_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif isinstance(m, nn.RNN) :\n",
    "        xavier_normal_(m.weight_ih_l0.data)\n",
    "        xavier_normal_(m.weight_hh_l0.data)\n",
    "        m.bias_ih_l0.data.fill_(0)\n",
    "        m.bias_hh_l0.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate DVRNN\n",
    "\n",
    "![Image of Yaktocat  https://github.ibm.com/vanstee/aicoc-ai-immersion/raw/master/nb_images/lstm_rnn.png \n",
    "![Image of Yaktocat    ../nb_images/lstm_rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html\n",
    "\n",
    "class DVRNN(nn.Module) :\n",
    "    def __init__(self,nf,tx,hs,nl) :\n",
    "        super(DVRNN,self).__init__()\n",
    "        self.name = \"DVRNN\"\n",
    "        self.tx=tx\n",
    "        self.num_features=nf\n",
    "        self.hidden_size=hs\n",
    "        self.num_layers=nl\n",
    "        self.rnn = nn.RNN(nf, hs, nl)\n",
    "        self.fc = nn.Linear(hs, 1)\n",
    "    \n",
    "    def forward(self, x, all_outputs=True):\n",
    "        bs=x.size()[1]\n",
    "        # Create Hidden init on the fly ...\n",
    "        print(x.size(), self.num_layers, bs, self.hidden_size)\n",
    "        hidden_init = torch.zeros(self.num_layers, bs, self.hidden_size).to(d)\n",
    "        x=x.to(d)\n",
    "\n",
    "        out1, hidden = self.rnn(x, hidden_init)\n",
    "         # batchsize hard coded\n",
    "        if(all_outputs == False) :\n",
    "            out3 = torch.zeros(1,bs,1).to(d) \n",
    "            for b in range(bs) :\n",
    "                out2 = out1[self.tx-1,b].view(-1)\n",
    "                out3[0,b,0] = self.fc(out2)\n",
    "        else :\n",
    "            #print(\"batch_size={}\".format(bs))\n",
    "            out3 = torch.zeros(self.tx,bs,1).to(d) \n",
    "            for i in range(self.tx) :\n",
    "                for b in range(bs) :\n",
    "                    out2 = out1[i,b,:].view(-1)\n",
    "                    out3[i,b,0] = self.fc(out2)\n",
    "        return out3,hidden.detach()\n",
    "    \n",
    "    # reset all parameters of model \n",
    "    def init_params(self) :\n",
    "        self.apply(weights_xavier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skip] Train RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastAI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://johaupt.github.io/python/fastai/pytorch/fastai_custom_network_module.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a fastai databunch from np array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Custom RNN\n",
    "# Build X, y\n",
    "# Added in time lagged y (c_prev)\n",
    "torch.manual_seed(0)\n",
    "NP=3008\n",
    "Tx = 70          # sequence length \n",
    "hidden_size = 50  # number of features of hidden state\n",
    "num_layers  = 1  # this is for stacked implementations.  Keep 1 for now\n",
    "batch_size = 16\n",
    "num_features = 4 # aka input_size, aka number of columns in X\n",
    "reset_prob = 0.05\n",
    "\n",
    "#hidden_rnn = torch.zeros(num_layers, batch_size, hidden_size).to(d)\n",
    "#hidden_lstm = (torch.zeros(num_layers, batch_size, hidden_size).to(d),torch.zeros(num_layers, batch_size, hidden_size).to(d))\n",
    "#dataset = CustomDataset(NP=NP,Tx=Tx)\n",
    "#dataloader = DataLoader(dataset, collate_fn=collate_fn, \n",
    "#                        batch_size=batch_size,shuffle=True,num_workers=30)\n",
    "def print_run() :\n",
    "    print(\"NP           : {}\".format(NP))\n",
    "    print(\"num_features : {}\".format(num_features))\n",
    "    print(\"Tx : {}\".format(Tx))\n",
    "    print(\"hidden_size : {}\".format(hidden_size))\n",
    "    print(\"num_layers : {}\".format(num_layers))\n",
    "    print(\"batch_size : {}\".format(batch_size))\n",
    "    print(\"reset_prob : {}\".format(reset_prob))\n",
    "print_run()\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "dvrnn = DVRNN(num_features,Tx,hidden_size,num_layers).to(d)\n",
    "dvrnn.init_params()\n",
    "\n",
    "#dvlstm = DVLSTM(num_features,Tx,hidden_size,num_layers).to(d)\n",
    "#dvlstm.init_params()\n",
    "\n",
    "#dvrnn.train()\n",
    "#optimizer = optim.SGD(dvrnn.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBunch.create(dataset=,collate_fn=)\n",
    "from fastai.basic_data import *\n",
    "dataset0 = CustomDataset(NP=NP,Tx=70,num_features=num_features)\n",
    "dataset1 = CustomDataset(NP=NP,Tx=70,num_features=num_features)\n",
    "(x0,y0) = dataset[0]\n",
    "#mdb=DataBunch.create(train_ds=dataset0,valid_ds=dataset1,collate_fn=collate_fn)\n",
    "dlt = DataLoader(dataset0, collate_fn=collate_fn, batch_size=batch_size,shuffle=True)\n",
    "dlv = DataLoader(dataset1, collate_fn=collate_fn, batch_size=batch_size,shuffle=True)\n",
    "mdb=DataBunch(train_dl=dlt,valid_dl=dlv,collate_fn=collate_fn)\n",
    "\n",
    "x,y = mdb.one_batch()\n",
    "#mdb.show_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset0, collate_fn=collate_fn, batch_size=batch_size,shuffle=True)\n",
    "(X,y) = next(iter(dl))\n",
    "dvrnn(X)\n",
    "#print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fastai.basic_train import *\n",
    "import fastai.train  \n",
    "from fastai.metrics import *\n",
    "learner = fastai.train.Learner(data=mdb, model=dvrnn, metrics=None) # ,metrics=accuracy)\n",
    "\n",
    "# def tabular_learner(data:DataBunch, layers:Collection[int], emb_szs:Dict[str,int]=None, metrics=None,\n",
    "#         ps:Collection[float]=None, emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, **learn_kwargs):\n",
    "#     \"Get a `Learner` using `data`, with `metrics`, including a `TabularModel` created using the remaining params.\"\n",
    "#     emb_szs = data.get_emb_szs(ifnone(emb_szs, {}))\n",
    "#     model = TabularModel(emb_szs, len(data.cont_names), out_sz=data.c, layers=layers, ps=ps, emb_drop=emb_drop,\n",
    "#                          y_range=y_range, use_bn=use_bn)\n",
    "#     return Learner(data, model, metrics=metrics, **learn_kwargs)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.lr_find()\n",
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.fit_one_cycle()\n",
    "#dir(learner)\n",
    "learner.lr_find()\n",
    "#learner.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(learner.data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)\n",
    "y.size()\n",
    "def xxx(*x) :\n",
    "    print(type(x))\n",
    "    print(x.size())\n",
    "\n",
    "xxx(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(1, 0.001, callbacks=None, wd=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code, not used ...\n",
    "\n",
    "# split_by_idxs\n",
    "#  ok, so here split__by_idxs requires 2 collections of indexes ..\n",
    "# train_idxs = range(0,10)\n",
    "# val_idxs = range(20,25)\n",
    "# db1 = FloatList(items=X,ignore_empty=True).\\\n",
    "#      split_by_idxs(train_idx=train_idxs, valid_idx=val_idxs) # .label_from_func(get_float_labels, label_cls=FloatList)\n",
    "\n",
    "## Databunch.add\n",
    "# .add(FloatList(items=X))  , add extra data here ...\n",
    "# ItemList class has all the goodies and methods implemented.  Look there for code examples\n",
    "\n",
    "# Example how to extend an existing datatype\n",
    "class NPList(FloatList) :\n",
    "    def __init__(self, items, classes=None, label_delim=None, **kwargs):\n",
    "        super().__init__(items, classes=classes, **kwargs)\n",
    "    \n",
    "    def show_xys(a,b,c) :\n",
    "        print(\"NotImplemented [yet]\")\n",
    "\n",
    "# Numpy Arrays\n",
    "NP=1000\n",
    "ii,X,y,columns = create_data_set(NP=NP)\n",
    "tv_split=range(700,1000) # Indexes 700-1000 will be used for validation ...\n",
    "\n",
    "# Using Datablocks API\n",
    "db = NPList(items=X).split_by_idx(tv_split)._label_from_list(y, label_cls=NPList)\n",
    "db.train.get(1)\n",
    "print(db) # .num_parts\n",
    "mdb = db.databunch()\n",
    "mdb.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
