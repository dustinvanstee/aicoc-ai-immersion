{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your custom image classifier using FastAI and WML-CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was copied and modified for this lab from this source https://github.com/fastai/course-v3 \n",
    "\n",
    "Welcome to lesson 1! For those of you who are using a Jupyter Notebook for the first time, you can learn about this useful tool in a tutorial we prepared specially for you; click `File`->`Open` now and click `00_notebook_tutorial.ipynb`. \n",
    "\n",
    "In this lesson we will build our first image classifier from scratch, and see if we can achieve world-class results. Let's dive in!\n",
    "\n",
    "Every notebook starts with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:13.186674Z",
     "start_time": "2020-05-21T01:46:13.115558Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "# For Using GPU's\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About our Class Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import all the necessary packages. We are going to work with the [fastai V1 library](http://www.fast.ai/2018/10/02/fastai-ai/) which sits on top of [Pytorch 1.3](https://hackernoon.com/pytorch-1-0-468332ba5163). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.\n",
    "\n",
    "For this class, we are using WML-CE running in the Worldwide Client Experience Center Cloud, or CECC for short.  To access and environment, simply browse to this website and request a Power8 or Power9 environment.\n",
    "\n",
    "https://www.ibm.com/it-infrastructure/services/cecc-portal/web/Catalog\n",
    "\n",
    "* Note : To get PowerAI up and running we have a special setup script in our github repo ... \n",
    "\n",
    "https://github.ibm.com/vanstee/aicoc-ai-immersion/blob/master/FastAI/setup_fastai.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:18.050229Z",
     "start_time": "2020-05-21T01:46:15.880005Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# utility print function\n",
    "def nprint(mystring) :\n",
    "    print(\"**{}** : {}\".format(sys._getframe(1).f_code.co_name,mystring))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Configuration\n",
    "\n",
    "This data structure below will hold all the settings for our class.  Its handy to have a simple dictionary contain all your project settings to keep organized.  We have include an override capability to these default settings so that you can customize your project. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:19.415600Z",
     "start_time": "2020-05-21T01:46:19.267814Z"
    }
   },
   "outputs": [],
   "source": [
    "def getconfig(cfg_in={}):\n",
    "    cfg = {}\n",
    "    cfg[\"bs\"] = 16\n",
    "    cfg[\"image_dir\"] = \"/home/cecuser/FastAI/images\"\n",
    "    cfg[\"classes\"] = [\"cars\",\"busses\",\"trucks\"]\n",
    "    cfg[\"num_images\"] = {\"train\":200,\"valid\":20,\"test\":20}\n",
    "    cfg[\"d_partitions\"] = list(cfg[\"num_images\"].keys())                 \n",
    "    cfg[\"jpeginfo\"] =\"/home/cecuser/aicoc-ai-immersion/FastAI/jpeginfo\"\n",
    "    cfg[\"repo_dir\"] = \"/home/cecuser/aicoc-ai-immersion/FastAI\"    \n",
    "   \n",
    "    # overwrite configs if passed\n",
    "    for (k,v) in cfg_in.items() :\n",
    "        nprint(\"Overriding Config {}:{} with {}\".format(k,cfg[k],v))\n",
    "        cfg[k] = v\n",
    "    return cfg\n",
    "\n",
    "# bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to build our own dataset !!  Think of 3 categories you would like to classify images.  In this example, we will use \n",
    "* busses\n",
    "* trucks \n",
    "* cars\n",
    "\n",
    "We will use an open source tool called *googliser* to download our images from google images.\n",
    "\n",
    "For a Covid-19 based example you could make your classes something like \n",
    "* \"people wearing masks\"\n",
    "* \"people posing street\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:25.636142Z",
     "start_time": "2020-05-21T01:46:25.498381Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "# @@ Students : Customize this cell with your custom classes for image classification\n",
    "################################################################################################\n",
    "\n",
    "# Overrides for lab\n",
    "\n",
    "mycfg = {\n",
    "    \"classes\":[\"people wearing masks\",\"people posing street\",\"people skateboarding\",\"people on bikes\"],  ## <<- CLASS Enter your search terms here \n",
    "    \"d_partitions\":[\"train\"],\n",
    "}\n",
    "cfg=getconfig(mycfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Some Directories to hold our data \n",
    "\n",
    "FastAI is very flexible and help you label your image data in all sorts of ways.  You might have a bunch of images and a csv file with the labels.  You might have your images organized by folder with the folder name being the labels.  \n",
    "\n",
    "To see all the supported methods check out this link..\n",
    "https://docs.fast.ai/vision.data.html#ImageDataBunch.from_folder\n",
    "\n",
    "For our class, we are going to organize our data by folder.\n",
    "\n",
    "TODO : insert image here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:26.768144Z",
     "start_time": "2020-05-21T01:46:26.623882Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helpers to make directories\n",
    "def class_folder_name(base,d_part,cls) :\n",
    "    return base+\"/\"+d_part+\"/\"+ cls.replace(\" \",\"_\")\n",
    "\n",
    "def makeDirIfNotExist(directory) :\n",
    "    if not os.path.exists(directory):  \n",
    "        nprint(\"Making directory {}\".format(directory))\n",
    "        os.makedirs(directory) \n",
    "    else :\n",
    "        nprint(\"Directory {} already exists .. \".format(directory))\n",
    "\n",
    "# Build directory hierarchy\n",
    "#   [train|valid|test ]\n",
    "#    -----------------> [class1 | class2 | class...]\n",
    "for d_part in cfg[\"d_partitions\"] :\n",
    "    for cls in cfg[\"classes\"] :\n",
    "        directory=class_folder_name(cfg['image_dir'],d_part,cls)\n",
    "        makeDirIfNotExist(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Googliser here.  \n",
    "This handy utility will download our images from google images.  We will clone the repo from git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:31.006545Z",
     "start_time": "2020-05-21T01:46:29.056225Z"
    }
   },
   "outputs": [],
   "source": [
    "# install googliser\n",
    "def install_googliser():\n",
    "    googliser_directory = cfg['repo_dir']+\"/googliser\"\n",
    "    if not os.path.exists(googliser_directory):  \n",
    "        nprint(\"Installing Googliser here : {} \".format(googliser_directory))\n",
    "        os.chdir(cfg['repo_dir'])\n",
    "        !git clone https://github.com/teracow/googliser\n",
    "    else :\n",
    "        nprint(\"Googliser already installed here : {} \".format(googliser_directory))\n",
    "\n",
    "    googliser = cfg['repo_dir']+\"/googliser/googliser.sh\"\n",
    "\n",
    "    return googliser \n",
    "googliser = install_googliser()\n",
    "!ls {googliser}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many images should we grab ?\n",
    "\n",
    "Luckily not too many.. it always depends on the project, but we are going to use a pre-training deep learning network when we perform training.  Since that network was already trained on over 1 million images, we don't need to supply too many for our task.  This is why transfer learning is so powerful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:46:38.629963Z",
     "start_time": "2020-05-21T01:46:38.493306Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg['num_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:58:03.781841Z",
     "start_time": "2020-05-21T01:53:48.870512Z"
    }
   },
   "outputs": [],
   "source": [
    "# The code below will download files to train folder only to avoid duplicate downloads.  \n",
    "# We then move a few files over.  This can be done manually or programatically.  For our example\n",
    "# we will let FastAI do the work for us!\n",
    "\n",
    "def download_images(cfg):\n",
    "    utility_dir = cfg['repo_dir']\n",
    "    for d_p in cfg[\"d_partitions\"] : # train only for now ..\n",
    "        for cls in cfg[\"classes\"] :\n",
    "            current_dir =class_folder_name(cfg['image_dir'],d_p,cls)\n",
    "            #os.chdir(current_dir)\n",
    "            os.chdir(utility_dir)\n",
    "            command = googliser + \\\n",
    "                      \" --o {}\".format(current_dir) +\\\n",
    "                      \" --phrase \\\"{}\\\"\".format(cls) + \\\n",
    "                      \" --parallel 50 --upper-size 500000 --lower-size 2000 \" + \\\n",
    "                      \" -n {}\".format(cfg['num_images'][d_p]) + \\\n",
    "                      \" --format jpg --timeout 15 --safesearch-off \"\n",
    "            nprint(command)\n",
    "            !{command}\n",
    "    nprint(\"Downloads complete!\")\n",
    "download_images(cfg)\n",
    "\n",
    "# This will take ~5 mins depending on how many classes / images we are grabbing... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up downloaded images that are not proper jpeg format .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:02.760371Z",
     "start_time": "2020-05-21T02:04:58.417462Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean with jpeginfo! \n",
    "def clean_up_bad_jpegs(cfg,extension):\n",
    "    os.chdir(cfg['image_dir'])\n",
    "    nprint(\"Search for Error files in {}......\".format(cfg['image_dir']))\n",
    "    # handle both jpg //jpeg\n",
    "    command = \"find . -name \\\"*.{}\\\"\".format(extension) + \\\n",
    "      \" | xargs -i {}\".format(cfg[\"jpeginfo\"]) + \\\n",
    "      \" -c {} | grep ERROR\"\n",
    "    nprint(\"Running command : {}\".format(command))\n",
    "    !{command}\n",
    "    nprint(\"Removing any error files listed above\")\n",
    "    command = command + ' | cut -d \" \" -f1 | xargs -i rm {} '\n",
    "    nprint(\"Running command : {}\".format(command))\n",
    "    !{command}\n",
    "    nprint(\"Done\")\n",
    "clean_up_bad_jpegs(cfg,\"jpg\")\n",
    "clean_up_bad_jpegs(cfg,\"jpeg\")\n",
    "# find . -name \"*.jpg,\" | xargs -i ./jpeginfo -c {}\n",
    "# find . -name \"*.jpg\" | xargs -i ./jpeginfo -c {} | grep ERROR | cut -d \" \" -f1 | xargs -i rm {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:15.277621Z",
     "start_time": "2020-05-21T02:05:15.141839Z"
    }
   },
   "outputs": [],
   "source": [
    "#path = untar_data(URLs.PETS); path\n",
    "path = Path(cfg['image_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:16.071387Z",
     "start_time": "2020-05-21T02:05:15.930557Z"
    }
   },
   "outputs": [],
   "source": [
    "path.ls()\n",
    "#cfg['image_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do when we approach a problem is to take a look at the data. We _always_ need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Taking a look at the data means understanding how the data directories are structured, what the labels are and what some sample images look like.\n",
    "\n",
    "The main difference between the handling of image classification datasets is the way labels are stored. In this particular dataset, labels are stored in the filenames themselves. We will need to extract them to be able to classify the images into the correct categories. Fortunately, the fastai library has a handy function made exactly for this, `ImageDataBunch.from_name_re` gets the labels from the filenames using a [regular expression](https://docs.python.org/3.6/library/re.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Bunch\n",
    "Fastai has a number of methods to create a data bunch. Lets look at some of the documentation using **doc** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:18.810321Z",
     "start_time": "2020-05-21T02:05:18.637759Z"
    }
   },
   "outputs": [],
   "source": [
    "#doc(ImageDataBunch)\n",
    "doc(ImageDataBunch.from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:19.987726Z",
     "start_time": "2020-05-21T02:05:19.588470Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.fast.ai/vision.data.html#ImageDataBunch.from_folder\n",
    "## Important, batch size should be set lower than the number of images you have\n",
    "data = ImageDataBunch.from_folder(path=cfg['image_dir'],\n",
    "                train=\"train\",valid_pct=0.20,no_check=True,\n",
    "                size=224,num_workers=4,bs=cfg[\"bs\"]).normalize(imagenet_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:21.576923Z",
     "start_time": "2020-05-21T02:05:20.760806Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:28.786114Z",
     "start_time": "2020-05-21T02:05:22.471045Z"
    }
   },
   "outputs": [],
   "source": [
    "data.show_batch(rows=4, figsize=(9,9))\n",
    "#data.show_batch(figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:09:14.674840Z",
     "start_time": "2020-05-21T00:09:13.935391Z"
    }
   },
   "outputs": [],
   "source": [
    "data.label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:19:20.386149Z",
     "start_time": "2020-05-21T00:19:20.325547Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start training our model. We will use a [convolutional neural network](http://cs231n.github.io/convolutional-networks/) backbone and a fully connected head with a single hidden layer as a classifier. Don't know what these things mean? Not to worry, we will dive deeper in the coming lessons. For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories (in this case, it will have 37 outputs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:46:33.820750Z",
     "start_time": "2020-05-21T00:46:31.590605Z"
    }
   },
   "outputs": [],
   "source": [
    "#create learner\n",
    "learn = cnn_learner(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:46:35.690740Z",
     "start_time": "2020-05-21T00:46:35.631435Z"
    }
   },
   "outputs": [],
   "source": [
    "# save pretrained model ..\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:47:43.699696Z",
     "start_time": "2020-05-21T00:46:41.190064Z"
    }
   },
   "outputs": [],
   "source": [
    "# dont worry about the #na#, as long as we get a plot in the next section, great!\n",
    "learn.lr_find() # num_it=36, stop_div=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:47:52.128578Z",
     "start_time": "2020-05-21T00:47:51.219147Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:48:55.662099Z",
     "start_time": "2020-05-21T00:48:04.998457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run 5 epochs (can do more if still getting better train / val)\n",
    "# FILL IN THE RANGE BASE ON YOUR LRFIND RESULT\n",
    "learn.fit_one_cycle(5, max_lr=slice(5e-5,1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what results we have got. \n",
    "\n",
    "We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. \n",
    "\n",
    "Furthermore, when we plot the confusion matrix, if we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:39.836027Z",
     "start_time": "2020-05-21T00:49:37.436285Z"
    }
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:41:46.459609Z",
     "start_time": "2020-05-21T00:41:46.365878Z"
    }
   },
   "outputs": [],
   "source": [
    "doc(interp.plot_top_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:42.782670Z",
     "start_time": "2020-05-21T00:49:39.839318Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(19,11),heatmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:54.230285Z",
     "start_time": "2020-05-21T00:49:53.761842Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
    "interp.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:43:41.308113Z",
     "start_time": "2020-05-21T00:43:41.242637Z"
    }
   },
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreezing, fine-tuning, and learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model is working as we expect it to, we will *unfreeze* our model and train some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:50:13.668843Z",
     "start_time": "2020-05-21T00:50:13.433183Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('stage-1')\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:51:26.494235Z",
     "start_time": "2020-05-21T00:50:35.370260Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:51:55.362403Z",
     "start_time": "2020-05-21T00:51:55.305023Z"
    }
   },
   "outputs": [],
   "source": [
    "#learn.save('stage-2')\n",
    "#learn.load('stage-1');\n",
    "#learn.unfreeze(-2)\n",
    "#learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:52:03.513502Z",
     "start_time": "2020-05-21T00:52:00.842407Z"
    }
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "len(data.valid_ds)==len(losses)==len(idxs)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty accurate model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. It will be explained later in the course and you can learn the details in the [resnet paper](https://arxiv.org/pdf/1512.03385.pdf)).\n",
    "\n",
    "Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. To help it along, let's us use larger images too, since that way the network can see more detail. We reduce the batch size a bit since otherwise this larger network will require more GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Assignment \n",
    "Can you redo the training above with a different pre-trained model ???  See this page for some ideas\n",
    "\n",
    "https://docs.fast.ai/vision.models.html\n",
    "\n",
    "* Hint : in a a code cell type  models.\\<<tab\\>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(cnn_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = cnn_learner(data, FILL_IN_HERE!!, metrics=error_rate)\n",
    "learn = cnn_learner(data, models.vgg11_bn, metrics=error_rate)\n",
    "# model.alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2) # 2 epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-custom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets continue to tune ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it doesn't get better results, you can always go back to your previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1-50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Example :  Loading Data from PAIV / IVI \n",
    "\n",
    "So you want to train on some data that maybe you labelled in another tool ?  No problem.  Here we show how you could read in data exported from PAIV and classifying in this tool ...\n",
    "\n",
    "For our IBM Visual Insights Example, we can just run a nice utility to reformat the output.  For convenience, we added a **Bananas Dataset** to our repo to play with .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:49.836988Z",
     "start_time": "2020-05-21T02:05:49.550953Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(cfg[\"repo_dir\"])\n",
    "!ls *.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip our bananas data and convert to images in sub-directories\n",
    "\n",
    "When you export data from IVI, you get a single zip file.  When you unzip this file, you get a singular directory with a metadata file called prop.json.  We have a utility that will read that prop.json and create a new directory with sorted images... lets see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:52.951797Z",
     "start_time": "2020-05-21T02:05:51.214902Z"
    }
   },
   "outputs": [],
   "source": [
    "# unzip the Bananas.zip to /tmp/bananas_ivi directory\n",
    "!sudo yum install -y unzip\n",
    "!unzip -o -d /tmp Bananas.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:05:57.740639Z",
     "start_time": "2020-05-21T02:05:57.457417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now run our handy script !\n",
    "!git clone https://github.com/dustinvanstee/powerai-vision-utils.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:06:35.231563Z",
     "start_time": "2020-05-21T02:06:00.561224Z"
    }
   },
   "outputs": [],
   "source": [
    "!conda install -y scikit-learn # dependency to run our utility ..\n",
    "!python powerai-vision-utils/reorganize_exported_dataset.py --directory_in /tmp/Bananas --directory_out /tmp/bananas_fastai/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T02:06:35.525584Z",
     "start_time": "2020-05-21T02:06:35.236582Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /tmp/bananas_fastai/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:24:54.157118Z",
     "start_time": "2020-05-21T01:24:54.102035Z"
    }
   },
   "outputs": [],
   "source": [
    "# New project config!\n",
    "mycfg = {\n",
    "    \"image_dir\" : \"/tmp/bananas_fastai\",\n",
    "    \"classes\":[\"black\",\"green\",\"overripe\",\"yellows\"],  ## <<- CLASS Enter your search terms here \n",
    "    \"d_partitions\":[\"train\"],\n",
    "}\n",
    "ivicfg=getconfig(mycfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:26:18.604961Z",
     "start_time": "2020-05-21T01:26:18.550243Z"
    }
   },
   "outputs": [],
   "source": [
    "# New Image Path ..\n",
    "path = Path(ivicfg[\"image_dir\"])\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:26:34.084287Z",
     "start_time": "2020-05-21T01:26:33.872522Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /tmp/bananas_fastai/black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:31:52.999836Z",
     "start_time": "2020-05-21T01:31:51.615944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define some transforms and setup data bunch\n",
    "tfms = get_transforms(do_flip=True)\n",
    "data = ImageDataBunch.from_folder(path,train=\"train\", ds_tfms=tfms, size=100, valid_pct=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:31:59.024107Z",
     "start_time": "2020-05-21T01:31:56.635724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display some images\n",
    "data.show_batch(rows=3, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:32:18.278670Z",
     "start_time": "2020-05-21T01:32:01.962642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup a CNN learner\n",
    "learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:37:49.387623Z",
     "start_time": "2020-05-21T01:36:31.721924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Learning rate search\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:38:07.781630Z",
     "start_time": "2020-05-21T01:38:06.986162Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:38:44.342747Z",
     "start_time": "2020-05-21T01:38:29.458447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run fit one cycle for 5 epochs\n",
    "learn.fit_one_cycle(5,slice(1e-5,3e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:40:22.933844Z",
     "start_time": "2020-05-21T01:40:21.228262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets see how well we did ... \n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "losses,idxs = interp.top_losses()\n",
    "len(data.valid_ds)==len(losses)==len(idxs)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you can now build a pretty darn good classifier in less than one hour!\n",
    "\n",
    "Credits \n",
    "* FastAI Team\n",
    "* Bob Chesebrough / Dustin VanStee - AICoC Data science team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
